---
title: "Time-Normalized Traffic Comparisons"
output: html_notebook
---

The code below uses Google Analytics data to compare a series of pages from the point of launch (as detected by the first day each page received meaningful traffic). This is based on an [example posted on dartistics.com](http://www.dartistics.com/googleanalytics/int-time-normalized.html).

## Setup

Load the necessary packages, authenticate, and set the basics.

```{r setup, message=FALSE, warning=FALSE}

# Load the necessary libraries. 
if (!require("pacman")) install.packages("pacman")
pacman::p_load(googleAnalyticsR,  # How we actually get the Google Analytics data
               tidyverse,         # Includes dplyr, ggplot2, and others; very key!
               devtools,          # Generally handy
               plotly,            # We're going to make the charts interactive
               RColorBrewer,      # For our color palette
               scales)            # Useful for some number formatting in the visualizations

# Authorize GA. Depending on if you've done this already and a .ga-httr-oauth file has
# been saved or not, this may pop you over to a browser to authenticate.
ga_auth(token = ".ga-httr-oauth")

# Set the view ID and the date range. If you want to, you can swap out the Sys.getenv()
# call and just replace that with a hardcoded value for the view ID. 
view_id <- Sys.getenv("GA_VIEW_ID")
start_date <- Sys.Date() - 365        # The last year
end_date <- Sys.Date() - 1            # Yesterday

# We're going to have R try to figure out when a page actually launched by finding the
# first day (in the data that is pulled) where the page had at least X unique pageviews.
first_day_pageviews_min <- 2

# We also don't want to include pages that have total traffic (daily unique pageviews)
# that are relatively low. So, set a cutoff for those.
total_unique_pageviews_cutoff <- 200

# We want to set how many "days from launch" we want to include in our display.
days_live_range <- 60

# Set up a base "theme" for the visualizations. This doesn't come into play for a while
# good to go ahead and define early on.

theme_base <- theme_light() + 
  theme(text = element_text(family = "Arial", colour = "gray20"), 
        panel.grid = element_blank(),
        panel.border = element_blank(),
        legend.position = "none",
        panel.grid.major.y = element_line(color = "gray80"),
        axis.ticks = element_blank(),
        axis.line.x = element_line(color="gray50"))


```

## Pull the Data

```{r data-pull, message=FALSE, warning=FALSE}

# Create a dimension filter object. See ?dim_filter() for details. You WILL want to update the
# "expressions" value to be a regular expression that filters to the appropriate set of content
# on your site.
page_filter_object <- dim_filter("pagePath", 
                                   operator = "REGEXP",
                                   expressions = "/blog/.+")

# Now, put that filter object into a filter clause. The "operator" argument is moot in this case,
# but required.
page_filter <- filter_clause_ga4(list(page_filter_object),
                                          operator = "AND")

# Pull the data. See ?google_analytics() for additional parameters. 
ga_data <- google_analytics(viewId = view_id,
                            date_range = c(start_date, end_date),
                            metrics = "uniquePageviews",
                            dimensions = c("date","pagePath"),
                            dim_filters = page_filter,
                            anti_sample = TRUE)

# Go ahead and do a quick inspection of the data that was returned. This isn't required,
# but it's a good check along the way.
head(ga_data)
```

## Explaining the Challenge

Here's the issue: when we look at pages in normal, calendar time, it's hard to compare them.

```{r challenge, message=FALSE, warning=FALSE, fig.width=10, fig.height=4.5}

# Filter to two pages that will illustrate the point
ga_data_two_pages <- ga_data %>% 
  filter(pagePath == "/blog/the-data-literacy-triad/" | pagePath=="/blog/tim-wilson-100/")

# Plot traffic by day to those two pages
gg <- ggplot(ga_data_two_pages, aes(x=date, y=uniquePageviews, color = pagePath)) +
  geom_line() +
  scale_colour_manual(values = c("#0060af", "#F58220")) +
  scale_y_continuous(labels=comma, expand=c(0,0)) +                     # Include commas in the y-axis numbers
    expand_limits(y=0) +
  labs(x = "Date", y = "Unique Pageviews") +
  theme_base

ggplotly(gg)


```


## Time-Normalize the Data

The solution is...time-normalization!

### Munge/Wrangle the Data

Here's where we're going to have some fun. We're going to need to find the "first day of meaningful traffic" (the first day in the data set that each page has at least `first_day_pageviews_min` unique pageviews).

```{r munging, message=FALSE, warning=FALSE}

# Find the first date for each. This is actually a little tricky, so we're going to write a 
# function that takes each page as an input, filters the data to just include those
# pages, finds the first page, and then puts a "from day 1" count on that data and returns it.
normalize_date_start <- function(page){
  
  # Filter all the data to just be the page being processed
  ga_data_single_page <- ga_data %>% filter(pagePath == page)
  
  # Find the first value in the result that is greater than first_day_pageviews_min. In many
  # cases, this will be the first row, but, if there has been testing/previews before it
  # actually goes live, some noise may sneak in where the page may have been live, technically,
  # but wasn't actually being considered live.
  first_live_row <- min(which(ga_data_single_page$uniquePageviews > first_day_pageviews_min))
  
  # If the first detected live date is the same as the start date, then this is an 
  # existing page rather than one that launched during the year
  page_type <- ifelse(ga_data_single_page$date[first_live_row] == start_date, "Existing", "Launched in Period")
  
  # Filter the data to start with that page
  ga_data_single_page <- ga_data_single_page[first_live_row:nrow(ga_data_single_page),]
  
  # As the content ages, there may be days that have ZERO traffic. Those days won't show up as
  # rows at all in our data. So, we actually need to create a data frame that includes
  # all dates in the range from the "launch" until the last day traffic was recorded. There's
  # a little trick here where we're going to make a column with a sequence of *dates* (date) and,
  # with a slightly different "seq," a "days_live" that corresponds with each date.
  normalized_results <- data.frame(date = seq.Date(from = min(ga_data_single_page$date), 
                                                   to = max(ga_data_single_page$date), 
                                                   by = "day"),
                                   days_live = seq(min(ga_data_single_page$date):
                                                     max(ga_data_single_page$date)),
                                   page = page) %>% 
    
    # Join back to the original data to get the uniquePageviews
    left_join(ga_data_single_page) %>%
    
    # Replace the "NAs" (days in the range with no uniquePageviews) with 0s (because 
    # that's exactly what happened on those days!)
    mutate(uniquePageviews = ifelse(is.na(uniquePageviews), 0, uniquePageviews)) %>% 
    
    # We're going to plot both the daily pageviews AND the cumulative total pageviews,
    # so let's add the cumulative total
    mutate(cumulative_uniquePageviews = cumsum(uniquePageviews)) %>% 
    
    # Add the page type
    mutate(page_type = page_type) %>% 
    
    # Grab just the columns we need for our visualization!
    select(page, page_type, days_live, uniquePageviews, cumulative_uniquePageviews)
}

# We want to run the function above on each page in our data set. So, we need to get a list
# of those pages. We don't want to include pages with low traffic overall, which we set
# earlier as the 'total_unique_pageviews_cutoff' value, so let's also filter our
# list to only include the ones that exceed that cutoff. 
pages_list <- ga_data %>% 
  group_by(pagePath) %>% summarise(total_traffic = sum(uniquePageviews)) %>% 
  filter(total_traffic > total_unique_pageviews_cutoff)

# The first little bit of magic can now occur. We'll run our normalize_date_start function on
# each value in our list of pages and get a data frame back that has our time-normalized
# traffic by page!
ga_data_normalized <- map_dfr(pages_list$pagePath, normalize_date_start)


# We specified earlier -- in the `days_live_range` object -- how many "days from launch" we
# actually want to include, so let's do one final round of filtering to only include those
# rows.
ga_data_normalized <- ga_data_normalized %>% filter(days_live <= days_live_range)

# Check out the result of our handiwork
head(ga_data_normalized)

```

### Visualize the Data!

We're going to do two visualizations here:

* **Unique Pageviews by Day from Launch** -- typically, this will show a big jump for the first day or two, and then a precipitous dropoff afterwards. If that's not the case, well, good on ya'! That means you're getting sustained value from your content marketing!
* **Cumulative Unique Pageviews by Day from Launch** -- this will be an easier chart to read, typically, and you can simply look from top to bottom to see which pages have generated the most traffic over time (in the first X days since they launched)

**IMPORTANT:** There may be pages that actually launched before the start of the data pulled. Those pages are going to wind up with the first day in the overall data set treated as their "Day 1," so they likely won't show that initial spike (because it occurred so long ago that it's not included in the data).

Because these will be somewhat messy line charts, we're also going to use the `plotly` package to make them interactive to that the user can mouse over a line and find out exactly what page it is. 




#### Plot Unique Pageviews by Day from Launch

This is the visualization that simply plots *uniquePageviews* by day. It can be a little messy to digest (but it can also be eye-opening as to how quickly interest in a particular piece of content drops off).

```{r visualization_1, message=FALSE, warning=FALSE, fig.width=10, fig.height=4.5}

# We're just going to use same two pages we started with
ga_data_normalized_two_pages <- ga_data_normalized %>% 
  filter(page == "/blog/the-data-literacy-triad/" | page=="/blog/tim-wilson-100/")

# Create the plot
gg <- ggplot(ga_data_normalized_two_pages, mapping=aes(x = days_live, y = uniquePageviews, color=page)) +
  geom_line() +                                          # The main "plot" operation
  scale_y_continuous(labels=comma, expand=c(0,0)) +                     # Include commas in the y-axis numbers
    expand_limits(y=0) +
  scale_colour_manual(values = c("#0060af", "#F58220")) +
  labs(x = "# of Days Since Page Launched",
       y = "Unique Pageviews") +
  theme_base


# Output the plot. We're wrapping it in ggplotly so we will get some interactivity in the plot.
ggplotly(gg)

```

#### Plot Cumulative Unique Pageviews by Day from Launch

This is the visualization that looks at the _cumulative_ *unique pageviews* for the first X days following the launch (or the first X days of the total evaluation period if the page launched before the start of the evaluation period).

```{r visualization_2, message=FALSE, warning=FALSE, fig.width=10, fig.height=4.5}

# Create the plot
gg <- ggplot(ga_data_normalized_two_pages, mapping=aes(x = days_live, y = cumulative_uniquePageviews, color=page)) +
  geom_line() +                                          # The main "plot" operation
  scale_y_continuous(labels=comma, expand=c(0,0)) +                     # Include commas in the y-axis numbers
  expand_limits(y=0) +
  scale_colour_manual(values = c("#0060af", "#F58220")) +
  labs(x = "# of Days Since Page Launched",
       y = "Cumulative Unique Pageviews") +
  theme_base

# Output the plot. We're wrapping it in ggplotly so we will get some interactivity in the plot.

ggplotly(gg)

```

#### Show this for All Data

```{r visualization_3, message=FALSE, warning=FALSE, fig.width=10, fig.height=4.5}

# Create the plot
gg <- ggplot(ga_data_normalized, mapping=aes(x = days_live, y = cumulative_uniquePageviews, color=page)) +
  geom_line() +                                          # The main "plot" operation
  scale_y_continuous(labels=comma, expand=c(0,0)) +                     # Include commas in the y-axis numbers
  expand_limits(y=0) +
  labs(x = "# of Days Since Page Launched",
       y = "Cumulative Unique Pageviews") +
  theme_base

# Output the plot. We're wrapping it in ggplotly so we will get some interactivity in the plot.

ggplotly(gg)

```